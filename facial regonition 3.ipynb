{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff351deb-ca0f-4375-993d-b05c71ca63b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your name:  Akhilesh PAndey\n"
     ]
    }
   ],
   "source": [
    "#here we used free library for training the data\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load OpenCV's built-in face detector\n",
    "#here we import cascadeclassifier the with  help of cv2\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# make dataset directory \n",
    "dataset_path = \"face_dataset\"\n",
    "if not os.path.exists(dataset_path):\n",
    "    os.makedirs(dataset_path)        #create the dataset directory it does not exist\n",
    "\n",
    "name = input(\"Enter your name: \")\n",
    "person_path = os.path.join(dataset_path, name)\n",
    "os.makedirs(person_path, exist_ok=True)    # create a directory for the person if it does not exist \n",
    "\n",
    "cap = cv2.VideoCapture(0)      #open the web camera \n",
    "count = 0   # intialize the image count\n",
    "\n",
    "while count < 100:  # Collect 100 face images\n",
    "    ret, frame = cap.read()     # read a frame from the webcam\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #convert the frame to gray scale\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)  #detect face from the frame \n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = gray[y:y+h, x:x+w]   # extract the face region from the gray scale frame\n",
    "        face = cv2.resize(face, (100, 100))  #resize the face to 100*100 pixel\n",
    "        cv2.imwrite(f\"{person_path}/{count}.jpg\", face) # save the face image to the person directory\n",
    "        count += 1 # increment the image count\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)  #draw a rectangle around the face \n",
    "\n",
    "    cv2.imshow(\"Face Collection\", frame) # display the frame with detected the face \n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"): # exit the loop if q is press \n",
    "        break\n",
    "\n",
    "cap.release() # release the webcam\n",
    "cv2.destroyAllWindows() # close all open cv windows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533422e0-7b36-4c04-8bce-5d237daac6cd",
   "metadata": {},
   "source": [
    "# Train the KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73d04641-1f23-4908-974c-105f896c05cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete and model saved!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsClassifier  # here all type of algorithm  is used like svm,knn etc in sklearn\n",
    "import pickle\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "dataset_path = \"face_dataset\"\n",
    "data = []        # list to store image the data\n",
    "labels =[]         # list to store labels correspoing to each image \n",
    "names = [name for name in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, name))]  # Filter out non-directory entries\n",
    "\n",
    "for idx, name in enumerate(names):\n",
    "    person_path = os.path.join(dataset_path, name)\n",
    "    for file in os.listdir(person_path):\n",
    "        file_path = os.path.join(person_path, file)\n",
    "        if os.path.isfile(file_path):  # Ensure it's a file\n",
    "            img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE) # read the image in gray scale \n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (100, 100))\n",
    "                data.append(img.flatten())  # Convert to 1D array\n",
    "                labels.append(idx)          # add label index corresponing to the person \n",
    "            else:\n",
    "                print(f\"Failed to load image: {file}\")\n",
    "\n",
    "data = np.array(data)    # convert the data list to numpy array\n",
    "labels = np.array(labels) # convert label list to numpy array\n",
    "\n",
    "# Train KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)   # react knn classifier with 5 neighbour\n",
    "knn.fit(data, labels)  # train the classfier with image,data and label\n",
    "\n",
    "# Save the model\n",
    "with open(\"face_recognition_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump((knn, names), f)    # save the model and name to a file  \n",
    "\n",
    "print(\"Training complete and model saved!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50138620-3dec-4080-8137-2ea9aa963555",
   "metadata": {},
   "source": [
    "# Real Time Face Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dc8260-b02e-4743-b5fb-d256a9a758ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attendance marked for ritik\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "# Load face detector\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Load trained model\n",
    "with open(\"face_recognition_model.pkl\", \"rb\") as f:\n",
    "    knn, names = pickle.load(f)      #load the knn model name from the pickle file \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Attendance file\n",
    "attendance_file = \"attendance.csv\"     # make the csv file for attendance \n",
    "\n",
    "# Check if file exists, else create it\n",
    "if not os.path.exists(attendance_file):\n",
    "    with open(attendance_file, \"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Name\", \"Date\", \"Time\"])\n",
    "\n",
    "marked_names = set()  # Track marked names to avoid duplicate marking\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()    # read the frame from the webcam\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = gray[y:y+h, x:x+w]\n",
    "        face = cv2.resize(face, (100, 100))\n",
    "        face = face.flatten().reshape(1, -1)  # Prepare for KNN and convert to one d array and reshape  \n",
    "\n",
    "        label = knn.predict(face)[0] # pedict the label of the face using the knn model\n",
    "        name = names[label] # give the name correspoding to the pridicated the label\n",
    "\n",
    "        # Display name\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2) # display the name above the face\n",
    "\n",
    "        # Mark attendance if not already marked\n",
    "        if name not in marked_names:\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") # this is storing year,month and day in acolumn and hour,min and second in other column\n",
    "            with open(attendance_file, \"a\", newline=\"\") as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([name, timestamp.split()[0], timestamp.split()[1]])\n",
    "\n",
    "            print(f\"Attendance marked for {name}\")\n",
    "            marked_names.add(name)\n",
    "\n",
    "    cv2.imshow(\"Attendance System\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eab0623-c7cf-47fb-b619-dfe1d7647248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25622664-d00d-4309-aeef-40286af7354d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937d057d-f2c4-481a-a386-38da7de090f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ef7f71-076a-4df8-ae19-15a3dec24f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc0e7a0-052a-4d1f-aa3b-a1e95276643e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
